	.file	"multiple_rgroup-2.c"
	.option nopic
	.attribute arch, "rv32i2p1_m2p0_a2p1_f2p2_d2p2_c2p0_v1p0_zicsr2p0_zifencei2p0_zve32f1p0_zve32x1p0_zve64d1p0_zve64f1p0_zve64x1p0_zvl128b1p0_zvl32b1p0_zvl64b1p0"
	.attribute unaligned_access, 0
	.attribute stack_align, 16
	.text
	.align	1
	.globl	test_1_TYPE1_int16_t
	.type	test_1_TYPE1_int16_t, @function
test_1_TYPE1_int16_t:
	addi	sp,sp,-48
	lw	t5,56(sp)
	lh	t3,48(sp)
	lw	t6,52(sp)
	ble	t5,zero,.L1
	or	t1,a2,a1
	or	t1,a0,t1
	andi	t1,t1,15
	bne	t1,zero,.L3
	andi	a4,a4,0xff
	andi	a3,a3,0xff
	slli	a4,a4,8
	andi	a5,a5,0xff
	slli	a5,a5,16
	or	t4,a3,a4
	vsetvli	t1,zero,e8,m1,ta,ma
	li	t2,16777216
	addi	t2,t2,-1
	or	t1,t4,a5
	slli	a6,a6,24
	and	t1,t1,t2
	vmv.v.i	v1,0
	sw	s0,44(sp)
	vs1r.v	v1,0(sp)
	or	s0,t1,a6
	sw	s0,0(sp)
	lw	s0,4(sp)
	li	t4,-65536
	addi	t4,t4,255
	andi	t0,s0,-256
	or	t0,t0,a3
	and	s0,t0,t4
	li	t1,-16711680
	addi	t1,t1,-1
	or	s0,s0,a4
	and	t0,s0,t1
	or	t0,t0,a5
	and	t0,t0,t2
	or	s0,t0,a6
	sw	s0,4(sp)
	lw	s0,8(sp)
	slli	a7,a7,16
	li	t0,65536
	srli	a7,a7,16
	addi	t0,t0,-1
	sw	s1,40(sp)
	slli	s1,t3,16
	vsetvli	t3,zero,e16,m1,ta,ma
	sw	s2,36(sp)
	sw	s3,32(sp)
	andi	s2,s0,-256
	addi	t3,sp,16
	and	s0,a7,t0
	vmv.v.i	v1,0
	or	s0,s0,s1
	vs1r.v	v1,0(t3)
	sw	s0,16(sp)
	lw	s0,20(sp)
	li	t3,-65536
	or	s2,s2,a3
	and	s0,t3,s0
	and	s3,s2,t4
	or	s0,s0,a7
	or	s3,s3,a4
	and	s0,s0,t0
	and	s2,s3,t1
	or	s0,s0,s1
	or	s2,s2,a5
	sw	s0,20(sp)
	lw	s0,12(sp)
	and	s2,s2,t2
	or	s2,s2,a6
	sw	s2,8(sp)
	andi	s2,s0,-256
	lw	s0,24(sp)
	or	s2,s2,a3
	and	t4,s2,t4
	and	s0,t3,s0
	or	a3,s0,a7
	and	a3,a3,t0
	or	t4,t4,a4
	or	a4,a3,s1
	sw	a4,24(sp)
	lw	a4,28(sp)
	and	t1,t4,t1
	or	t1,t1,a5
	and	t3,t3,a4
	or	t3,t3,a7
	and	t1,t1,t2
	and	t3,t3,t0
	or	a4,t1,a6
	sw	a4,12(sp)
	or	a4,t3,s1
	slli	a7,t5,2
	sw	a4,28(sp)
	li	a5,48
	vsetvli	a4,zero,e32,m1,ta,ma
	mv	t3,a7
	vmv.v.x	v1,t6
	bltu	a7,a5,.L14
	li	a5,32
	addi	t3,t3,-48
	mv	t4,a7
	bltu	a7,a5,.L15
.L5:
	li	a5,16
	addi	t4,t4,-32
	mv	t1,a7
	bltu	a7,a5,.L16
.L6:
	addi	t1,t1,-16
.L7:
	vsetvli	a6,a7,e8,m4,tu,mu
	vl1re8.v	v2,0(sp)
	addi	a4,a0,16
	vsetvli	zero,a6,e8,m1,ta,ma
	vse8.v	v2,0(a0)
	addi	a5,a0,32
	vsetvli	a3,t1,e8,m4,tu,mu
	vsetvli	zero,a3,e8,m1,ta,ma
	vse8.v	v2,0(a4)
	addi	t6,a0,48
	vsetvli	a4,t4,e8,m4,tu,mu
	vsetvli	zero,a4,e8,m1,ta,ma
	vse8.v	v2,0(a5)
	srli	t5,a6,1
	vsetvli	a5,t3,e8,m4,tu,mu
	addi	s0,sp,16
	vsetvli	zero,a5,e8,m1,ta,ma
	vse8.v	v2,0(t6)
	vl1re16.v	v2,0(s0)
	srli	t6,a3,1
	vsetvli	zero,t5,e16,m1,ta,ma
	addi	t5,a1,16
	vse16.v	v2,0(a1)
	vsetvli	zero,t6,e16,m1,ta,ma
	srli	t6,a4,1
	vse16.v	v2,0(t5)
	addi	t5,a1,32
	vsetvli	zero,t6,e16,m1,ta,ma
	srli	t6,a5,1
	vse16.v	v2,0(t5)
	addi	t5,a1,48
	vsetvli	zero,t6,e16,m1,ta,ma
	vse16.v	v2,0(t5)
	srli	t5,a6,2
	vsetvli	zero,t5,e32,m1,ta,ma
	addi	t6,a2,16
	vse32.v	v1,0(a2)
	srli	a3,a3,2
	vsetvli	zero,a3,e32,m1,ta,ma
	addi	t5,a2,32
	vse32.v	v1,0(t6)
	srli	a4,a4,2
	addi	a3,a2,48
	vsetvli	zero,a4,e32,m1,ta,ma
	srli	a5,a5,2
	vse32.v	v1,0(t5)
	sub	a7,a7,a6
	vsetvli	zero,a5,e32,m1,ta,ma
	vse32.v	v1,0(a3)
	sub	t1,t1,a6
	sub	t4,t4,a6
	sub	t3,t3,a6
	addi	a0,a0,64
	addi	a1,a1,64
	addi	a2,a2,64
	bne	a7,zero,.L7
	lw	s0,44(sp)
	lw	s1,40(sp)
	lw	s2,36(sp)
	lw	s3,32(sp)
.L1:
	addi	sp,sp,48
	jr	ra
.L16:
	li	t1,16
	j	.L6
.L15:
	li	t4,32
	li	a5,16
	addi	t4,t4,-32
	mv	t1,a7
	bgeu	a7,a5,.L6
	j	.L16
.L14:
	li	t3,48
	li	a5,32
	addi	t3,t3,-48
	mv	t4,a7
	bgeu	a7,a5,.L5
	j	.L15
.L3:
	slli	t5,t5,2
	add	t5,a0,t5
.L9:
	sb	a3,0(a0)
	sb	a4,1(a0)
	sb	a5,2(a0)
	sb	a6,3(a0)
	sh	a7,0(a1)
	sh	t3,2(a1)
	sw	t6,0(a2)
	addi	a0,a0,4
	addi	a1,a1,4
	addi	a2,a2,4
	bne	a0,t5,.L9
	addi	sp,sp,48
	jr	ra
	.size	test_1_TYPE1_int16_t, .-test_1_TYPE1_int16_t
	.align	1
	.globl	test_1_TYPE1_uint16_t
	.type	test_1_TYPE1_uint16_t, @function
test_1_TYPE1_uint16_t:
	addi	sp,sp,-48
	lw	t1,56(sp)
	lhu	t4,48(sp)
	lw	t5,52(sp)
	ble	t1,zero,.L17
	or	t3,a2,a1
	or	t3,a0,t3
	andi	t3,t3,15
	bne	t3,zero,.L19
	slli	a4,a4,8
	slli	a5,a5,16
	or	t6,a3,a4
	vsetvli	t3,zero,e8,m1,ta,ma
	li	t2,16777216
	addi	t2,t2,-1
	or	t3,t6,a5
	slli	a6,a6,24
	and	t3,t3,t2
	vmv.v.i	v1,0
	sw	s0,44(sp)
	vs1r.v	v1,0(sp)
	or	s0,t3,a6
	sw	s0,0(sp)
	lw	s0,4(sp)
	li	t6,-65536
	addi	t6,t6,255
	andi	t0,s0,-256
	or	t0,t0,a3
	and	s0,t0,t6
	li	t3,-16711680
	addi	t3,t3,-1
	or	s0,s0,a4
	and	t0,s0,t3
	or	t0,t0,a5
	and	t0,t0,t2
	or	s0,t0,a6
	sw	s0,4(sp)
	lw	s0,8(sp)
	li	t0,65536
	addi	t0,t0,-1
	sw	s2,36(sp)
	andi	s2,s0,-256
	slli	s0,t4,16
	vsetvli	t4,zero,e16,m1,ta,ma
	sw	s1,40(sp)
	sw	s3,32(sp)
	addi	t4,sp,16
	and	s1,a7,t0
	vmv.v.i	v1,0
	or	s1,s1,s0
	vs1r.v	v1,0(t4)
	sw	s1,16(sp)
	lw	s1,20(sp)
	li	t4,-65536
	or	s2,s2,a3
	and	s1,t4,s1
	and	s3,s2,t6
	or	s1,s1,a7
	or	s3,s3,a4
	and	s1,s1,t0
	and	s2,s3,t3
	or	s1,s1,s0
	or	s2,s2,a5
	sw	s1,20(sp)
	lw	s1,12(sp)
	and	s2,s2,t2
	or	s2,s2,a6
	sw	s2,8(sp)
	andi	s2,s1,-256
	lw	s1,24(sp)
	or	s2,s2,a3
	and	t6,s2,t6
	and	s1,t4,s1
	or	a3,s1,a7
	and	a3,a3,t0
	or	t6,t6,a4
	or	a4,a3,s0
	sw	a4,24(sp)
	lw	a4,28(sp)
	and	t3,t6,t3
	or	t3,t3,a5
	and	t4,t4,a4
	and	t3,t3,t2
	or	t4,t4,a7
	or	a4,t3,a6
	and	t4,t4,t0
	sw	a4,12(sp)
	or	a4,t4,s0
	slli	t1,t1,2
	sw	a4,28(sp)
	li	a5,48
	vsetvli	a4,zero,e32,m1,ta,ma
	mv	t3,t1
	vmv.v.x	v1,t5
	bltu	t1,a5,.L29
	li	a5,32
	addi	t3,t3,-48
	mv	t4,t1
	bltu	t1,a5,.L30
.L21:
	li	a5,16
	addi	t4,t4,-32
	mv	a7,t1
	bltu	t1,a5,.L31
.L22:
	addi	a7,a7,-16
.L23:
	vsetvli	a6,t1,e8,m4,tu,mu
	vl1re8.v	v2,0(sp)
	addi	a4,a0,16
	vsetvli	zero,a6,e8,m1,ta,ma
	vse8.v	v2,0(a0)
	addi	a5,a0,32
	vsetvli	a3,a7,e8,m4,tu,mu
	vsetvli	zero,a3,e8,m1,ta,ma
	vse8.v	v2,0(a4)
	addi	t6,a0,48
	vsetvli	a4,t4,e8,m4,tu,mu
	vsetvli	zero,a4,e8,m1,ta,ma
	vse8.v	v2,0(a5)
	srli	t5,a6,1
	vsetvli	a5,t3,e8,m4,tu,mu
	addi	s0,sp,16
	vsetvli	zero,a5,e8,m1,ta,ma
	vse8.v	v2,0(t6)
	vl1re16.v	v2,0(s0)
	srli	t6,a3,1
	vsetvli	zero,t5,e16,m1,ta,ma
	addi	t5,a1,16
	vse16.v	v2,0(a1)
	vsetvli	zero,t6,e16,m1,ta,ma
	srli	t6,a4,1
	vse16.v	v2,0(t5)
	addi	t5,a1,32
	vsetvli	zero,t6,e16,m1,ta,ma
	srli	t6,a5,1
	vse16.v	v2,0(t5)
	addi	t5,a1,48
	vsetvli	zero,t6,e16,m1,ta,ma
	vse16.v	v2,0(t5)
	srli	t5,a6,2
	vsetvli	zero,t5,e32,m1,ta,ma
	addi	t6,a2,16
	vse32.v	v1,0(a2)
	srli	a3,a3,2
	vsetvli	zero,a3,e32,m1,ta,ma
	addi	t5,a2,32
	vse32.v	v1,0(t6)
	srli	a4,a4,2
	addi	a3,a2,48
	vsetvli	zero,a4,e32,m1,ta,ma
	srli	a5,a5,2
	vse32.v	v1,0(t5)
	sub	t1,t1,a6
	vsetvli	zero,a5,e32,m1,ta,ma
	vse32.v	v1,0(a3)
	sub	a7,a7,a6
	sub	t4,t4,a6
	sub	t3,t3,a6
	addi	a0,a0,64
	addi	a1,a1,64
	addi	a2,a2,64
	bne	t1,zero,.L23
	lw	s0,44(sp)
	lw	s1,40(sp)
	lw	s2,36(sp)
	lw	s3,32(sp)
.L17:
	addi	sp,sp,48
	jr	ra
.L31:
	li	a7,16
	j	.L22
.L30:
	li	t4,32
	li	a5,16
	addi	t4,t4,-32
	mv	a7,t1
	bgeu	t1,a5,.L22
	j	.L31
.L29:
	li	t3,48
	li	a5,32
	addi	t3,t3,-48
	mv	t4,t1
	bgeu	t1,a5,.L21
	j	.L30
.L19:
	slli	t1,t1,2
	add	t1,a0,t1
.L25:
	sb	a3,0(a0)
	sb	a4,1(a0)
	sb	a5,2(a0)
	sb	a6,3(a0)
	sh	a7,0(a1)
	sh	t4,2(a1)
	sw	t5,0(a2)
	addi	a0,a0,4
	addi	a1,a1,4
	addi	a2,a2,4
	bne	a0,t1,.L25
	addi	sp,sp,48
	jr	ra
	.size	test_1_TYPE1_uint16_t, .-test_1_TYPE1_uint16_t
	.align	1
	.globl	test_1_TYPE1_int32_t
	.type	test_1_TYPE1_int32_t, @function
test_1_TYPE1_int32_t:
	addi	sp,sp,-64
	lw	t1,80(sp)
	lw	t3,64(sp)
	lw	t5,72(sp)
	lw	t6,76(sp)
	ble	t1,zero,.L32
	addi	t0,t1,-1
	li	t4,6
	bleu	t0,t4,.L34
	or	t4,a2,a1
	or	t4,a0,t4
	andi	t4,t4,15
	beq	t4,zero,.L44
.L34:
	slli	t1,t1,3
	add	t1,a0,t1
.L40:
	sh	a3,0(a0)
	sh	a4,2(a0)
	sh	a5,4(a0)
	sh	a6,6(a0)
	sw	a7,0(a1)
	sw	t3,4(a1)
	sw	t5,0(a2)
	sw	t6,4(a2)
	addi	a0,a0,8
	addi	a1,a1,8
	addi	a2,a2,8
	bne	a0,t1,.L40
.L32:
	addi	sp,sp,64
	jr	ra
.L44:
	sw	s0,60(sp)
	slli	t2,a3,16
	li	s0,65536
	addi	s0,s0,-1
	vsetvli	t4,zero,e16,m1,ta,ma
	srli	t2,t2,16
	slli	a4,a4,16
	and	a3,t2,s0
	addi	t4,sp,8
	or	a3,a3,a4
	vmv.v.i	v1,0
	vs1r.v	v1,0(t4)
	sw	a3,8(sp)
	lw	a3,12(sp)
	li	t4,-65536
	slli	a5,a5,16
	and	t0,t4,a3
	srli	a5,a5,16
	or	t0,t0,a5
	slli	a6,a6,16
	and	t0,t0,s0
	or	a3,t0,a6
	sw	a3,12(sp)
	lw	a3,16(sp)
	sw	t3,28(sp)
	sw	t3,36(sp)
	and	a3,t4,a3
	or	a3,a3,t2
	and	a3,a3,s0
	or	a4,a3,a4
	sw	a4,16(sp)
	lw	a4,20(sp)
	sw	a7,24(sp)
	sw	a7,32(sp)
	and	t4,t4,a4
	or	a5,t4,a5
	and	t4,a5,s0
	or	a4,t4,a6
	sw	a4,20(sp)
	sw	t5,40(sp)
	sw	t6,44(sp)
	slli	a5,t1,2
	addi	s0,sp,40
	li	a3,24
	vsetvli	a4,zero,e64,m1,ta,ma
	mv	t3,a5
	vlse64.v	v1,0(s0),zero
	bltu	a5,a3,.L45
	li	a4,16
	addi	t3,t3,-24
	mv	t4,a5
	bltu	a5,a4,.L46
.L36:
	li	a4,8
	addi	t4,t4,-16
	mv	t1,a5
	bltu	a5,a4,.L47
.L37:
	addi	t1,t1,-8
.L38:
	addi	a3,sp,8
	vsetvli	a4,a5,e8,m2,tu,mu
	vl1re16.v	v2,0(a3)
	addi	a6,a0,16
	vsetvli	zero,a4,e16,m1,ta,ma
	vse16.v	v2,0(a0)
	addi	a3,a0,32
	vsetvli	a7,t1,e8,m2,tu,mu
	vsetvli	zero,a7,e16,m1,ta,ma
	vse16.v	v2,0(a6)
	addi	t6,a0,48
	vsetvli	a6,t4,e8,m2,tu,mu
	vsetvli	zero,a6,e16,m1,ta,ma
	vse16.v	v2,0(a3)
	srli	t5,a4,1
	vsetvli	a3,t3,e8,m2,tu,mu
	addi	s0,sp,24
	vsetvli	zero,a3,e16,m1,ta,ma
	vse16.v	v2,0(t6)
	vl1re32.v	v2,0(s0)
	srli	t6,a7,1
	vsetvli	zero,t5,e32,m1,ta,ma
	addi	t5,a1,16
	vse32.v	v2,0(a1)
	vsetvli	zero,t6,e32,m1,ta,ma
	srli	t6,a6,1
	vse32.v	v2,0(t5)
	addi	t5,a1,32
	vsetvli	zero,t6,e32,m1,ta,ma
	srli	t6,a3,1
	vse32.v	v2,0(t5)
	addi	t5,a1,48
	vsetvli	zero,t6,e32,m1,ta,ma
	vse32.v	v2,0(t5)
	srli	t5,a4,2
	vsetvli	zero,t5,e64,m1,ta,ma
	addi	t6,a2,16
	vse64.v	v1,0(a2)
	srli	a7,a7,2
	vsetvli	zero,a7,e64,m1,ta,ma
	addi	t5,a2,32
	vse64.v	v1,0(t6)
	srli	a6,a6,2
	addi	a7,a2,48
	vsetvli	zero,a6,e64,m1,ta,ma
	srli	a3,a3,2
	vse64.v	v1,0(t5)
	sub	a5,a5,a4
	vsetvli	zero,a3,e64,m1,ta,ma
	vse64.v	v1,0(a7)
	sub	t1,t1,a4
	sub	t4,t4,a4
	sub	t3,t3,a4
	addi	a0,a0,64
	addi	a1,a1,64
	addi	a2,a2,64
	bne	a5,zero,.L38
	lw	s0,60(sp)
	addi	sp,sp,64
	jr	ra
.L47:
	li	t1,8
	j	.L37
.L46:
	li	t4,16
	li	a4,8
	addi	t4,t4,-16
	mv	t1,a5
	bgeu	a5,a4,.L37
	j	.L47
.L45:
	li	t3,24
	li	a4,16
	addi	t3,t3,-24
	mv	t4,a5
	bgeu	a5,a4,.L36
	j	.L46
	.size	test_1_TYPE1_int32_t, .-test_1_TYPE1_int32_t
	.align	1
	.globl	test_1_TYPE1_uint32_t
	.type	test_1_TYPE1_uint32_t, @function
test_1_TYPE1_uint32_t:
	addi	sp,sp,-48
	lw	t1,64(sp)
	lw	t5,48(sp)
	lw	t3,56(sp)
	lw	t4,60(sp)
	ble	t1,zero,.L48
	addi	t0,t1,-1
	li	t6,6
	bleu	t0,t6,.L50
	or	t6,a2,a1
	or	t6,a0,t6
	andi	t6,t6,15
	beq	t6,zero,.L60
.L50:
	slli	t1,t1,3
	add	t1,a0,t1
.L56:
	sh	a3,0(a0)
	sh	a4,2(a0)
	sh	a5,4(a0)
	sh	a6,6(a0)
	sw	a7,0(a1)
	sw	t5,4(a1)
	sw	t3,0(a2)
	sw	t4,4(a2)
	addi	a0,a0,8
	addi	a1,a1,8
	addi	a2,a2,8
	bne	a0,t1,.L56
.L48:
	addi	sp,sp,48
	jr	ra
.L60:
	li	t0,65536
	addi	t0,t0,-1
	vsetvli	t6,zero,e16,m1,ta,ma
	slli	a4,a4,16
	and	t2,a3,t0
	addi	t6,sp,8
	or	t2,t2,a4
	vmv.v.i	v1,0
	vs1r.v	v1,0(t6)
	sw	t2,8(sp)
	lw	t2,12(sp)
	li	t6,-65536
	slli	a6,a6,16
	and	t2,t6,t2
	or	t2,t2,a5
	and	t2,t2,t0
	or	t2,t2,a6
	sw	t2,12(sp)
	lw	t2,16(sp)
	sw	t3,40(sp)
	sw	a7,24(sp)
	and	t2,t6,t2
	or	a3,t2,a3
	and	a3,a3,t0
	or	a4,a3,a4
	sw	a4,16(sp)
	lw	a4,20(sp)
	sw	t5,28(sp)
	sw	a7,32(sp)
	and	t6,t6,a4
	or	t6,t6,a5
	and	t6,t6,t0
	or	a5,t6,a6
	sw	a5,20(sp)
	sw	t4,44(sp)
	slli	a4,t1,2
	sw	t5,36(sp)
	addi	a6,sp,40
	li	a3,24
	vsetvli	a5,zero,e64,m1,ta,ma
	mv	t3,a4
	vlse64.v	v1,0(a6),zero
	bltu	a4,a3,.L61
	li	a5,16
	addi	t3,t3,-24
	mv	t4,a4
	bltu	a4,a5,.L62
.L52:
	li	a5,8
	addi	t4,t4,-16
	mv	t1,a4
	bltu	a4,a5,.L63
.L53:
	addi	t1,t1,-8
.L54:
	addi	a3,sp,8
	vsetvli	a5,a4,e8,m2,tu,mu
	vl1re16.v	v2,0(a3)
	addi	a6,a0,16
	vsetvli	zero,a5,e16,m1,ta,ma
	vse16.v	v2,0(a0)
	addi	a3,a0,32
	vsetvli	a7,t1,e8,m2,tu,mu
	vsetvli	zero,a7,e16,m1,ta,ma
	vse16.v	v2,0(a6)
	addi	t6,a0,48
	vsetvli	a6,t4,e8,m2,tu,mu
	vsetvli	zero,a6,e16,m1,ta,ma
	vse16.v	v2,0(a3)
	srli	t5,a5,1
	vsetvli	a3,t3,e8,m2,tu,mu
	vsetvli	zero,a3,e16,m1,ta,ma
	vse16.v	v2,0(t6)
	addi	t6,sp,24
	vl1re32.v	v2,0(t6)
	vsetvli	zero,t5,e32,m1,ta,ma
	srli	t6,a7,1
	vse32.v	v2,0(a1)
	addi	t5,a1,16
	vsetvli	zero,t6,e32,m1,ta,ma
	srli	t6,a6,1
	vse32.v	v2,0(t5)
	addi	t5,a1,32
	vsetvli	zero,t6,e32,m1,ta,ma
	srli	t6,a3,1
	vse32.v	v2,0(t5)
	addi	t5,a1,48
	vsetvli	zero,t6,e32,m1,ta,ma
	vse32.v	v2,0(t5)
	srli	t5,a5,2
	vsetvli	zero,t5,e64,m1,ta,ma
	addi	t6,a2,16
	vse64.v	v1,0(a2)
	srli	a7,a7,2
	vsetvli	zero,a7,e64,m1,ta,ma
	addi	t5,a2,32
	vse64.v	v1,0(t6)
	srli	a6,a6,2
	addi	a7,a2,48
	vsetvli	zero,a6,e64,m1,ta,ma
	srli	a3,a3,2
	vse64.v	v1,0(t5)
	sub	a4,a4,a5
	vsetvli	zero,a3,e64,m1,ta,ma
	vse64.v	v1,0(a7)
	sub	t1,t1,a5
	sub	t4,t4,a5
	sub	t3,t3,a5
	addi	a0,a0,64
	addi	a1,a1,64
	addi	a2,a2,64
	bne	a4,zero,.L54
	addi	sp,sp,48
	jr	ra
.L63:
	li	t1,8
	j	.L53
.L62:
	li	t4,16
	li	a5,8
	addi	t4,t4,-16
	mv	t1,a4
	bgeu	a4,a5,.L53
	j	.L63
.L61:
	li	t3,24
	li	a5,16
	addi	t3,t3,-24
	mv	t4,a4
	bgeu	a4,a5,.L52
	j	.L62
	.size	test_1_TYPE1_uint32_t, .-test_1_TYPE1_uint32_t
	.ident	"GCC: (GNU) 13.0.1 20230324 (experimental)"
